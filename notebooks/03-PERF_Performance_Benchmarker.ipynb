{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-header",
   "metadata": {},
   "source": [
    "# üî¨ Notebook 04-PERF ‚Äî CivicPulse Performance Benchmarker\n",
    "\n",
    "**Purpose**: Sweep batch sizes, patch sizes, hidden channels, and load modes across your\n",
    "already-processed data from Notebooks 00‚Äì03 to find the optimal `.env` / `src/config.py` values\n",
    "for your hardware.\n",
    "\n",
    "**Data required** (produced by NB 00-03):\n",
    "| File | Produced by |\n",
    "|------|-------------|\n",
    "| `data/processed/india_sample.h5` | NB 02 |\n",
    "| `data/processed/telangana_population_sequence.npy` | NB 01 |\n",
    "| `data/processed/maharashtra_population_sequence.npy` | NB 01 |\n",
    "| `data/processed/india_pop_clipped_<year>.tif` | NB 03 |\n",
    "\n",
    "**What you get**: A results table + recommendation printed at the end.\n",
    "Copy the winner values straight into your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-manual-controls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Manual controls loaded\n",
      "  LOAD_MODE        : normal\n",
      "  DEVICE_OVERRIDE  : cpu\n",
      "  BATCH_SIZES      : [4, 8, 16, 32]\n",
      "  PATCH_SIZES      : [32, 64, 128, 256]\n",
      "  HIDDEN_CHANNELS  : [16, 32, 64]\n",
      "  NUM_LAYERS       : [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  ‚úèÔ∏è  MANUAL CONTROLS  ‚Äî edit these, then Run All\n",
    "# ============================================================\n",
    "\n",
    "# --- Load mode ---------------------------------------------------\n",
    "# \"hdf5\"   ‚Üí lazy-load chunks (low RAM, laptop-safe)\n",
    "# \"normal\" ‚Üí full numpy in RAM (fast on 32GB+ machines)\n",
    "LOAD_MODE = \"normal\"   # <-- change if needed\n",
    "\n",
    "# --- Device override ---------------------------------------------\n",
    "# \"auto\"  ‚Üí use whatever src/config.py detects\n",
    "# \"cuda\"  ‚Üí force GPU\n",
    "# \"cpu\"   ‚Üí force CPU\n",
    "DEVICE_OVERRIDE = \"cpu\"\n",
    "\n",
    "# --- Batch sizes to sweep ----------------------------------------\n",
    "# Add / remove values to narrow the search\n",
    "BATCH_SIZES = [4, 8, 16,32]\n",
    "\n",
    "# --- Patch sizes to sweep ----------------------------------------\n",
    "PATCH_SIZES = [32, 64, 128, 256]\n",
    "\n",
    "# --- ConvLSTM hidden channels to sweep ---------------------------\n",
    "HIDDEN_CHANNELS_LIST = [16, 32, 64]\n",
    "\n",
    "# --- Number of ConvLSTM layers to sweep --------------------------\n",
    "NUM_LAYERS_LIST = [1, 2]\n",
    "\n",
    "# --- How many forward+backward passes to time per config ---------\n",
    "# Higher = more accurate average; lower = faster benchmarking\n",
    "WARMUP_STEPS  = 2   # discarded\n",
    "TIMING_STEPS  = 5   # averaged\n",
    "\n",
    "# --- Enable/disable parts of the sweep ---------------------------\n",
    "RUN_BATCH_SWEEP    = True   # batch_size vs throughput\n",
    "RUN_PATCH_SWEEP    = True   # patch_size vs memory\n",
    "RUN_ARCH_SWEEP     = True   # hidden_channels + num_layers\n",
    "RUN_DATALOADER_BENCH = True # HDF5 vs numpy data loading speed\n",
    "\n",
    "# --- Output file for results -------------------------------------\n",
    "RESULTS_PATH = \"logs/perf_results.json\"\n",
    "\n",
    "# ============================================================\n",
    "print(\"‚úÖ Manual controls loaded\")\n",
    "print(f\"  LOAD_MODE        : {LOAD_MODE}\")\n",
    "print(f\"  DEVICE_OVERRIDE  : {DEVICE_OVERRIDE}\")\n",
    "print(f\"  BATCH_SIZES      : {BATCH_SIZES}\")\n",
    "print(f\"  PATCH_SIZES      : {PATCH_SIZES}\")\n",
    "print(f\"  HIDDEN_CHANNELS  : {HIDDEN_CHANNELS_LIST}\")\n",
    "print(f\"  NUM_LAYERS       : {NUM_LAYERS_LIST}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NOTEBOOK 04-PERF ‚Äî CivicPulse Performance Benchmarker\n",
      "======================================================================\n",
      "  Device   : cpu\n",
      "  LOAD_MODE: normal\n",
      "\n",
      "  ‚úÖ  india_sample.h5\n",
      "  ‚úÖ  telangana .npy\n",
      "  ‚úÖ  maharashtra .npy\n",
      "  ‚úÖ  India clipped TIFs : 5 files\n"
     ]
    }
   ],
   "source": [
    "import sys, os, time, json, gc, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚îÄ‚îÄ Optional: use TrainingConfig for baseline device detection ‚îÄ‚îÄ\n",
    "try:\n",
    "    from src.config import TrainingConfig, DeviceConfig\n",
    "    _base_config = TrainingConfig()\n",
    "    _auto_device = str(_base_config.DEVICE)\n",
    "except Exception:\n",
    "    _auto_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"‚ö†Ô∏è  src/config.py not importable ‚Äî using torch auto-detection\")\n",
    "\n",
    "# ‚îÄ‚îÄ Resolve device ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if DEVICE_OVERRIDE == \"auto\":\n",
    "    DEVICE = torch.device(_auto_device)\n",
    "else:\n",
    "    DEVICE = torch.device(DEVICE_OVERRIDE)\n",
    "\n",
    "# ‚îÄ‚îÄ Paths from NB 00-03 outputs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "H5_PATH         = Path(\"data/processed/india_sample.h5\")\n",
    "TEL_NPY         = Path(\"data/processed/telangana_population_sequence.npy\")\n",
    "MAHA_NPY        = Path(\"data/processed/maharashtra_population_sequence.npy\")\n",
    "INDIA_TIF_DIR   = Path(\"data/processed\")\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ Verify files exist ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOTEBOOK 04-PERF ‚Äî CivicPulse Performance Benchmarker\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Device   : {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"  GPU      : {torch.cuda.get_device_name(0)} ({vram:.1f} GB VRAM)\")\n",
    "print(f\"  LOAD_MODE: {LOAD_MODE}\")\n",
    "print()\n",
    "\n",
    "for p, label in [(H5_PATH, 'india_sample.h5'), (TEL_NPY, 'telangana .npy'),\n",
    "                 (MAHA_NPY, 'maharashtra .npy')]:\n",
    "    status = \"‚úÖ\" if p.exists() else \"‚ùå  MISSING\"\n",
    "    print(f\"  {status}  {label}\")\n",
    "\n",
    "india_tifs = sorted(INDIA_TIF_DIR.glob(\"india_pop_clipped_*.tif\"))\n",
    "print(f\"  {'‚úÖ' if india_tifs else '‚ö†Ô∏è '}  India clipped TIFs : {len(india_tifs)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-model-defs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model classes defined\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ ConvLSTM Cell (same architecture as NB04 onwards) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        pad = kernel_size // 2\n",
    "        self.conv_gates     = nn.Conv2d(in_channels + hidden_channels,\n",
    "                                        2 * hidden_channels, kernel_size, padding=pad)\n",
    "        self.conv_candidate = nn.Conv2d(in_channels + hidden_channels,\n",
    "                                        hidden_channels, kernel_size, padding=pad)\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        h, c = state\n",
    "        combined    = torch.cat([x, h], dim=1)\n",
    "        gates       = self.conv_gates(combined)\n",
    "        r, u        = torch.split(gates, self.hidden_channels, dim=1)\n",
    "        r, u        = torch.sigmoid(r), torch.sigmoid(u)\n",
    "        cand        = torch.tanh(self.conv_candidate(torch.cat([x, r * h], dim=1)))\n",
    "        new_c       = (1 - u) * c + u * cand\n",
    "        new_h       = torch.tanh(new_c) * u + (1 - u) * h\n",
    "        return new_h, new_c\n",
    "\n",
    "\n",
    "class ConvLSTMEncoderDecoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=64, num_layers=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers      = num_layers\n",
    "        self.encoder_cells   = nn.ModuleList([\n",
    "            ConvLSTMCell(in_channels if i == 0 else hidden_channels, hidden_channels, kernel_size)\n",
    "            for i in range(num_layers)])\n",
    "        self.decoder_cells   = nn.ModuleList([\n",
    "            ConvLSTMCell(hidden_channels, hidden_channels, kernel_size)\n",
    "            for _ in range(num_layers)])\n",
    "        self.output_conv     = nn.Conv2d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        h = [torch.zeros(B, self.hidden_channels, H, W, device=x.device, dtype=x.dtype)\n",
    "             for _ in range(self.num_layers)]\n",
    "        c = [torch.zeros_like(hh) for hh in h]\n",
    "        for t in range(T):\n",
    "            xt = x[:, t]\n",
    "            for l in range(self.num_layers):\n",
    "                h[l], c[l] = self.encoder_cells[l](xt if l == 0 else h[l-1], (h[l], c[l]))\n",
    "        for l in range(self.num_layers):\n",
    "            inp    = h[l-1] if l > 0 else h[0]\n",
    "            h[l], c[l] = self.decoder_cells[l](inp, (h[l], c[l]))\n",
    "        return self.output_conv(h[-1])   # (B, 1, H, W)\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"‚úÖ Model classes defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-datasets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Normal mode: loading full arrays...\n",
      "  Full array: (5, 1634, 997)  (33 MB)\n",
      "‚úÖ Dataset classes ready\n"
     ]
    }
   ],
   "source": [
    "class PopulationDatasetHDF5(Dataset):\n",
    "    \"\"\"Lazy HDF5 patch dataset (low RAM) ‚Äî from NB02 output.\"\"\"\n",
    "    def __init__(self, h5_path, patch_size=64, stride=None):\n",
    "        self.h5_path    = str(h5_path)\n",
    "        self.patch_size = patch_size\n",
    "        self.stride     = stride or patch_size // 2\n",
    "        with h5py.File(self.h5_path, \"r\") as h5:\n",
    "            _, H, W = h5[\"population_data\"].shape\n",
    "        self.patches = [(y, x)\n",
    "                        for y in range(0, H - patch_size, self.stride)\n",
    "                        for x in range(0, W - patch_size, self.stride)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y, x = self.patches[idx]\n",
    "        ps   = self.patch_size\n",
    "        with h5py.File(self.h5_path, \"r\") as h5:\n",
    "            data = h5[\"population_data\"][:, y:y+ps, x:x+ps]   # (T, ps, ps)\n",
    "        X  = torch.from_numpy(data[:4].copy()).float().unsqueeze(1)   # (4,1,H,W)\n",
    "        y_ = torch.from_numpy(data[4].copy()).float().unsqueeze(0)    # (1,H,W)\n",
    "        return X, y_\n",
    "\n",
    "\n",
    "class PopulationDatasetNormal(Dataset):\n",
    "    \"\"\"In-memory dataset from NB01 .npy outputs.\"\"\"\n",
    "    def __init__(self, data_array, patch_size=64, stride=None):\n",
    "        self.data       = data_array   # (T, H, W)\n",
    "        self.patch_size = patch_size\n",
    "        self.stride     = stride or patch_size // 2\n",
    "        T, H, W = data_array.shape\n",
    "        self.patches = [(y, x)\n",
    "                        for y in range(0, H - patch_size, self.stride)\n",
    "                        for x in range(0, W - patch_size, self.stride)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y, x = self.patches[idx]\n",
    "        ps   = self.patch_size\n",
    "        data = self.data[:, y:y+ps, x:x+ps]\n",
    "        X  = torch.from_numpy(data[:4].copy()).float().unsqueeze(1)\n",
    "        y_ = torch.from_numpy(data[4].copy()).float().unsqueeze(0)\n",
    "        return X, y_\n",
    "\n",
    "\n",
    "def make_dataset(patch_size, normal_data=None):\n",
    "    if LOAD_MODE == \"hdf5\":\n",
    "        return PopulationDatasetHDF5(H5_PATH, patch_size=patch_size)\n",
    "    else:\n",
    "        return PopulationDatasetNormal(normal_data, patch_size=patch_size)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Pre-load normal data once if needed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "_normal_data = None\n",
    "if LOAD_MODE == \"normal\":\n",
    "    print(\"üìÇ Normal mode: loading full arrays...\")\n",
    "    tel  = np.load(TEL_NPY)\n",
    "    maha = np.load(MAHA_NPY)\n",
    "    T, H1, W1 = tel.shape\n",
    "    _, H2, W2  = maha.shape\n",
    "    maxH, maxW = max(H1, H2), max(W1, W2)\n",
    "    tel  = np.pad(tel,  ((0,0),(0,maxH-H1),(0,maxW-W1)))\n",
    "    maha = np.pad(maha, ((0,0),(0,maxH-H2),(0,maxW-W2)))\n",
    "    _normal_data = np.concatenate([tel, maha], axis=1).astype(np.float32)\n",
    "    print(f\"  Full array: {_normal_data.shape}  ({_normal_data.nbytes/1e6:.0f} MB)\")\n",
    "else:\n",
    "    print(\"üìÇ HDF5 mode: data will be lazily loaded per patch\")\n",
    "    with h5py.File(H5_PATH, \"r\") as h5:\n",
    "        print(f\"  HDF5 shape: {h5['population_data'].shape}\")\n",
    "\n",
    "print(\"‚úÖ Dataset classes ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-helpers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Timing utilities ready\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "def gpu_memory_used_mb():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        return torch.cuda.memory_allocated() / 1e6\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def gpu_memory_peak_mb():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        return torch.cuda.max_memory_allocated() / 1e6\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def reset_peak_memory():\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "\n",
    "def time_forward_backward(model, X, y, criterion, steps, warmup):\n",
    "    \"\"\"\n",
    "    Returns (avg_ms_per_step, peak_vram_mb).\n",
    "    Catches OOM gracefully ‚Äî returns (None, None) on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model.train()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        reset_peak_memory()\n",
    "\n",
    "        for _ in range(warmup):\n",
    "            optimizer.zero_grad()\n",
    "            out  = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if DEVICE.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        for _ in range(steps):\n",
    "            optimizer.zero_grad()\n",
    "            out  = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if DEVICE.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed_ms = (time.perf_counter() - t0) * 1000 / steps\n",
    "        peak_mb    = gpu_memory_peak_mb()\n",
    "        return elapsed_ms, peak_mb\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            if DEVICE.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "            return None, None\n",
    "        raise\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "print(\"‚úÖ Timing utilities ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-batch-sweep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SWEEP A ‚Äî Batch Size  (patch=64, hidden=32, layers=2)\n",
      "======================================================================\n",
      " Batch     ms/step     samples/s     VRAM MB    Status\n",
      "------------------------------------------------------------\n",
      "     4       895.4           4.5         0.0  OK\n",
      "     8      1564.6           5.1         0.0  OK\n",
      "    16      2128.5           7.5         0.0  OK\n",
      "    32      3811.4           8.4         0.0  OK\n",
      "\n",
      "üèÜ Best batch size ‚Üí 32  (8.4 samples/s, 0 MB VRAM)\n",
      "   ‚ûú  Set CIVICPULSE_BATCH_SIZE=32 in .env\n"
     ]
    }
   ],
   "source": [
    "batch_results = []\n",
    "\n",
    "if not RUN_BATCH_SWEEP:\n",
    "    print(\"‚è≠Ô∏è  Batch sweep skipped (RUN_BATCH_SWEEP=False)\")\n",
    "else:\n",
    "    # Fixed config for this sweep\n",
    "    _PATCH = 64\n",
    "    _HC    = 32\n",
    "    _NL    = 2\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"SWEEP A ‚Äî Batch Size  (patch={_PATCH}, hidden={_HC}, layers={_NL})\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Batch':>6}  {'ms/step':>10}  {'samples/s':>12}  {'VRAM MB':>10}  {'Status':>8}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for bs in BATCH_SIZES:\n",
    "        gc.collect()\n",
    "        if DEVICE.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        model = ConvLSTMEncoderDecoder(\n",
    "            hidden_channels=_HC, num_layers=_NL).to(DEVICE)\n",
    "\n",
    "        # Synthetic batch matching patch size\n",
    "        X = torch.randn(bs, 4, 1, _PATCH, _PATCH, device=DEVICE)\n",
    "        y = torch.randn(bs, 1, _PATCH, _PATCH,     device=DEVICE)\n",
    "\n",
    "        ms, vram = time_forward_backward(\n",
    "            model, X, y, criterion, TIMING_STEPS, WARMUP_STEPS)\n",
    "\n",
    "        if ms is None:\n",
    "            print(f\"{bs:>6}  {'‚Äî':>10}  {'‚Äî':>12}  {'‚Äî':>10}  OOM\")\n",
    "            batch_results.append(dict(batch_size=bs, ms_per_step=None,\n",
    "                                      samples_per_sec=None, vram_mb=None, oom=True))\n",
    "        else:\n",
    "            sps = bs / (ms / 1000)\n",
    "            print(f\"{bs:>6}  {ms:>10.1f}  {sps:>12.1f}  {vram:>10.1f}  OK\")\n",
    "            batch_results.append(dict(batch_size=bs, ms_per_step=round(ms, 2),\n",
    "                                      samples_per_sec=round(sps, 1),\n",
    "                                      vram_mb=round(vram, 1), oom=False))\n",
    "\n",
    "        del model, X, y\n",
    "\n",
    "    # ‚îÄ‚îÄ Recommendation ‚îÄ‚îÄ\n",
    "    valid = [r for r in batch_results if not r[\"oom\"]]\n",
    "    if valid:\n",
    "        best = max(valid, key=lambda r: r[\"samples_per_sec\"])\n",
    "        print(f\"\\nüèÜ Best batch size ‚Üí {best['batch_size']}  \"\n",
    "              f\"({best['samples_per_sec']:.1f} samples/s, \"\n",
    "              f\"{best['vram_mb']:.0f} MB VRAM)\")\n",
    "        print(f\"   ‚ûú  Set CIVICPULSE_BATCH_SIZE={best['batch_size']} in .env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-patch-sweep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SWEEP B ‚Äî Patch Size  (batch=4, hidden=32, layers=2)\n",
      "======================================================================\n",
      "  Patch     ms/step     VRAM MB    Patches/epoch    Status\n",
      "-----------------------------------------------------------------\n",
      "     32       430.5         0.0            6,161  OK\n",
      "     64      1045.0         0.0            1,500  OK\n",
      "    128      1909.9         0.0              336  OK\n",
      "    256      7972.4         0.0               66  OK\n",
      "\n",
      "üèÜ Best patch size ‚Üí 256  (66 patches/epoch, 0 MB VRAM)\n",
      "   ‚ûú  Set CIVICPULSE_PATCH_SIZE=256 in .env\n"
     ]
    }
   ],
   "source": [
    "patch_results = []\n",
    "\n",
    "if not RUN_PATCH_SWEEP:\n",
    "    print(\"‚è≠Ô∏è  Patch sweep skipped (RUN_PATCH_SWEEP=False)\")\n",
    "else:\n",
    "    # Fixed config for this sweep\n",
    "    _BS = 4\n",
    "    _HC = 32\n",
    "    _NL = 2\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"SWEEP B ‚Äî Patch Size  (batch={_BS}, hidden={_HC}, layers={_NL})\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Patch':>7}  {'ms/step':>10}  {'VRAM MB':>10}  \"\n",
    "          f\"{'Patches/epoch':>15}  {'Status':>8}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    # Get spatial dims from HDF5\n",
    "    with h5py.File(H5_PATH, \"r\") as h5:\n",
    "        _, H_full, W_full = h5[\"population_data\"].shape\n",
    "\n",
    "    for ps in PATCH_SIZES:\n",
    "        gc.collect()\n",
    "        if DEVICE.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        model = ConvLSTMEncoderDecoder(\n",
    "            hidden_channels=_HC, num_layers=_NL).to(DEVICE)\n",
    "\n",
    "        X = torch.randn(_BS, 4, 1, ps, ps, device=DEVICE)\n",
    "        y = torch.randn(_BS, 1, ps, ps,    device=DEVICE)\n",
    "\n",
    "        ms, vram = time_forward_backward(\n",
    "            model, X, y, criterion, TIMING_STEPS, WARMUP_STEPS)\n",
    "\n",
    "        n_patches = ((H_full // (ps//2)) - 1) * ((W_full // (ps//2)) - 1)\n",
    "\n",
    "        if ms is None:\n",
    "            print(f\"{ps:>7}  {'‚Äî':>10}  {'‚Äî':>10}  {'‚Äî':>15}  OOM\")\n",
    "            patch_results.append(dict(patch_size=ps, ms_per_step=None,\n",
    "                                      vram_mb=None, n_patches=n_patches, oom=True))\n",
    "        else:\n",
    "            print(f\"{ps:>7}  {ms:>10.1f}  {vram:>10.1f}  {n_patches:>15,}  OK\")\n",
    "            patch_results.append(dict(patch_size=ps, ms_per_step=round(ms, 2),\n",
    "                                      vram_mb=round(vram, 1),\n",
    "                                      n_patches=n_patches, oom=False))\n",
    "\n",
    "        del model, X, y\n",
    "\n",
    "    valid = [r for r in patch_results if not r[\"oom\"]]\n",
    "    if valid:\n",
    "        # Balance: largest patch that fits without OOM gives fewest patches ‚Üí fastest epoch\n",
    "        best = max(valid, key=lambda r: r[\"patch_size\"])\n",
    "        print(f\"\\nüèÜ Best patch size ‚Üí {best['patch_size']}  \"\n",
    "              f\"({best['n_patches']:,} patches/epoch, {best['vram_mb']:.0f} MB VRAM)\")\n",
    "        print(f\"   ‚ûú  Set CIVICPULSE_PATCH_SIZE={best['patch_size']} in .env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-arch-sweep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SWEEP C ‚Äî Architecture  (batch=4, patch=64)\n",
      "======================================================================\n",
      "  Hidden   Layers      Params     ms/step     VRAM MB    Status\n",
      "----------------------------------------------------------------------\n",
      "      16        1      21,281       291.8         0.0  OK\n",
      "      16        2      49,025       647.4         0.0  OK\n",
      "      32        1      84,033       532.7         0.0  OK\n",
      "      32        2     194,817      1100.0         0.0  OK\n",
      "      64        1     333,953      1078.8         0.0  OK\n",
      "      64        2     776,705      2314.4         0.0  OK\n",
      "\n",
      "üèÜ Best arch ‚Üí hidden=64, layers=1  (333,953 params, 1078.8 ms/step)\n",
      "   ‚ûú  Set HIDDEN_CHANNELS=64, NUM_LAYERS=1 in src/config.py TrainingConfig\n"
     ]
    }
   ],
   "source": [
    "arch_results = []\n",
    "\n",
    "if not RUN_ARCH_SWEEP:\n",
    "    print(\"‚è≠Ô∏è  Architecture sweep skipped (RUN_ARCH_SWEEP=False)\")\n",
    "else:\n",
    "    _BS = 4\n",
    "    _PS = 64\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"SWEEP C ‚Äî Architecture  (batch={_BS}, patch={_PS})\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Hidden':>8}  {'Layers':>7}  {'Params':>10}  \"\n",
    "          f\"{'ms/step':>10}  {'VRAM MB':>10}  {'Status':>8}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for hc in HIDDEN_CHANNELS_LIST:\n",
    "        for nl in NUM_LAYERS_LIST:\n",
    "            gc.collect()\n",
    "            if DEVICE.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            model  = ConvLSTMEncoderDecoder(\n",
    "                hidden_channels=hc, num_layers=nl).to(DEVICE)\n",
    "            params = count_params(model)\n",
    "\n",
    "            X = torch.randn(_BS, 4, 1, _PS, _PS, device=DEVICE)\n",
    "            y = torch.randn(_BS, 1, _PS, _PS,    device=DEVICE)\n",
    "\n",
    "            ms, vram = time_forward_backward(\n",
    "                model, X, y, criterion, TIMING_STEPS, WARMUP_STEPS)\n",
    "\n",
    "            if ms is None:\n",
    "                print(f\"{hc:>8}  {nl:>7}  {params:>10,}  {'‚Äî':>10}  {'‚Äî':>10}  OOM\")\n",
    "                arch_results.append(dict(hidden=hc, layers=nl, params=params,\n",
    "                                         ms=None, vram=None, oom=True))\n",
    "            else:\n",
    "                print(f\"{hc:>8}  {nl:>7}  {params:>10,}  {ms:>10.1f}  {vram:>10.1f}  OK\")\n",
    "                arch_results.append(dict(hidden=hc, layers=nl, params=params,\n",
    "                                         ms=round(ms, 2), vram=round(vram, 1), oom=False))\n",
    "\n",
    "            del model, X, y\n",
    "\n",
    "    valid = [r for r in arch_results if not r[\"oom\"]]\n",
    "    if valid:\n",
    "        # Best = fastest that still has reasonable capacity (params >= 100k)\n",
    "        capable = [r for r in valid if r[\"params\"] >= 100_000] or valid\n",
    "        best    = min(capable, key=lambda r: r[\"ms\"])\n",
    "        print(f\"\\nüèÜ Best arch ‚Üí hidden={best['hidden']}, layers={best['layers']}  \"\n",
    "              f\"({best['params']:,} params, {best['ms']:.1f} ms/step)\")\n",
    "        print(f\"   ‚ûú  Set HIDDEN_CHANNELS={best['hidden']}, NUM_LAYERS={best['layers']} \"\n",
    "              f\"in src/config.py TrainingConfig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-dataloader-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SWEEP D ‚Äî DataLoader Throughput\n",
      "======================================================================\n",
      "  [  hdf5] india_sample.h5             36.8 ms/batch     108.6 samples/s\n",
      "  [normal] tel+maha .npy                0.6 ms/batch    6569.7 samples/s\n",
      "\n",
      "üèÜ Fastest load mode ‚Üí NORMAL  (6569.7 samples/s)\n",
      "   ‚ûú  Set CIVICPULSE_DATA_MODE=normal in .env  (also set LOAD_MODE=\"normal\" in NB04‚Äì07)\n"
     ]
    }
   ],
   "source": [
    "loader_results = []\n",
    "\n",
    "if not RUN_DATALOADER_BENCH:\n",
    "    print(\"‚è≠Ô∏è  DataLoader bench skipped (RUN_DATALOADER_BENCH=False)\")\n",
    "else:\n",
    "    _N_BATCHES = 20   # How many batches to iterate through per test\n",
    "    _BS        = 4\n",
    "    _PS        = 64\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SWEEP D ‚Äî DataLoader Throughput\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    configs_to_test = []\n",
    "    if H5_PATH.exists():\n",
    "        configs_to_test.append((\"hdf5\",   \"india_sample.h5\"))\n",
    "    if TEL_NPY.exists() and MAHA_NPY.exists():\n",
    "        configs_to_test.append((\"normal\", \"tel+maha .npy\"))\n",
    "\n",
    "    for mode, label in configs_to_test:\n",
    "        try:\n",
    "            if mode == \"hdf5\":\n",
    "                ds = PopulationDatasetHDF5(H5_PATH, patch_size=_PS)\n",
    "            else:\n",
    "                tel  = np.load(TEL_NPY)\n",
    "                maha = np.load(MAHA_NPY)\n",
    "                T,H1,W1 = tel.shape;  _,H2,W2 = maha.shape\n",
    "                mH,mW   = max(H1,H2), max(W1,W2)\n",
    "                tel     = np.pad(tel,  ((0,0),(0,mH-H1),(0,mW-W1)))\n",
    "                maha    = np.pad(maha, ((0,0),(0,mH-H2),(0,mW-W2)))\n",
    "                arr     = np.concatenate([tel, maha], axis=1).astype(np.float32)\n",
    "                ds      = PopulationDatasetNormal(arr, patch_size=_PS)\n",
    "\n",
    "            loader = DataLoader(ds, batch_size=_BS, shuffle=True,\n",
    "                                num_workers=0, pin_memory=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "            t0    = time.perf_counter()\n",
    "            count = 0\n",
    "            for X_b, y_b in loader:\n",
    "                _ = X_b.to(DEVICE), y_b.to(DEVICE)\n",
    "                count += 1\n",
    "                if count >= _N_BATCHES:\n",
    "                    break\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            ms_per  = elapsed * 1000 / count\n",
    "            sps     = (_BS * count) / elapsed\n",
    "\n",
    "            print(f\"  [{mode:>6}] {label:<22}  \"\n",
    "                  f\"{ms_per:>8.1f} ms/batch  {sps:>8.1f} samples/s\")\n",
    "            loader_results.append(dict(mode=mode, label=label,\n",
    "                                       ms_per_batch=round(ms_per,2),\n",
    "                                       samples_per_sec=round(sps,1)))\n",
    "        except Exception as e:\n",
    "            print(f\"  [{mode:>6}] ERROR: {e}\")\n",
    "            loader_results.append(dict(mode=mode, label=label, error=str(e)))\n",
    "\n",
    "    if loader_results:\n",
    "        valid_lr = [r for r in loader_results if \"error\" not in r]\n",
    "        if valid_lr:\n",
    "            best = max(valid_lr, key=lambda r: r[\"samples_per_sec\"])\n",
    "            print(f\"\\nüèÜ Fastest load mode ‚Üí {best['mode'].upper()}  \"\n",
    "                  f\"({best['samples_per_sec']:.1f} samples/s)\")\n",
    "            print(f\"   ‚ûú  Set CIVICPULSE_DATA_MODE={best['mode']} in .env  \"\n",
    "                  f\"(also set LOAD_MODE=\\\"{best['mode']}\\\" in NB04‚Äì07)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Full results saved ‚Üí logs/perf_results.json\n",
      "\n",
      "======================================================================\n",
      "RECOMMENDED .env VALUES\n",
      "======================================================================\n",
      "\n",
      "# ========================================\n",
      "# CIVICPULSE DEVICE CONFIGURATION\n",
      "# Generated by: 04-PERF Performance Notebook\n",
      "# ========================================\n",
      "\n",
      "CIVICPULSE_DEVICE=cpu\n",
      "CIVICPULSE_BATCH_SIZE=32\n",
      "CIVICPULSE_DATA_MODE=normal\n",
      "CIVICPULSE_PATCH_SIZE=256\n",
      "\n",
      "# ConvLSTM Architecture (set in src/config.py TrainingConfig)\n",
      "# HIDDEN_CHANNELS = 64\n",
      "# NUM_LAYERS      = 1\n",
      "\n",
      "üìã Copy the block above into your .env file.\n",
      "   Then update TrainingConfig in src/config.py for the architecture values.\n",
      "   Then set LOAD_MODE in Notebooks 04-07 to match CIVICPULSE_DATA_MODE.\n",
      "\n",
      "======================================================================\n",
      "PERFORMANCE BENCHMARKING COMPLETE ‚úÖ\n",
      "Next: Notebook 04 ‚Äî Model Architecture (use values above)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Collect all results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "all_results = dict(\n",
    "    device        = str(DEVICE),\n",
    "    load_mode     = LOAD_MODE,\n",
    "    batch_sweep   = batch_results,\n",
    "    patch_sweep   = patch_results,\n",
    "    arch_sweep    = arch_results,\n",
    "    loader_bench  = loader_results,\n",
    ")\n",
    "\n",
    "with open(RESULTS_PATH, \"w\") as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "print(f\"üíæ Full results saved ‚Üí {RESULTS_PATH}\")\n",
    "\n",
    "# ‚îÄ‚îÄ Generate .env recommendations ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDED .env VALUES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Best batch size\n",
    "valid_bs = [r for r in batch_results if not r.get(\"oom\")]\n",
    "best_bs  = max(valid_bs, key=lambda r: r[\"samples_per_sec\"])[\"batch_size\"] if valid_bs else \"auto\"\n",
    "\n",
    "# Best patch size\n",
    "valid_ps = [r for r in patch_results if not r.get(\"oom\")]\n",
    "best_ps  = max(valid_ps, key=lambda r: r[\"patch_size\"])[\"patch_size\"] if valid_ps else 200\n",
    "\n",
    "# Best data mode\n",
    "valid_lm = [r for r in loader_results if \"error\" not in r]\n",
    "best_lm  = max(valid_lm, key=lambda r: r[\"samples_per_sec\"])[\"mode\"] if valid_lm else LOAD_MODE\n",
    "\n",
    "# Best arch\n",
    "valid_ar = [r for r in arch_results if not r.get(\"oom\")]\n",
    "capable  = [r for r in valid_ar if r.get(\"params\", 0) >= 100_000] or valid_ar\n",
    "best_ar  = min(capable, key=lambda r: r[\"ms\"]) if capable else {\"hidden\": 32, \"layers\": 2}\n",
    "\n",
    "env_block = f\"\"\"\n",
    "# ========================================\n",
    "# CIVICPULSE DEVICE CONFIGURATION\n",
    "# Generated by: 04-PERF Performance Notebook\n",
    "# ========================================\n",
    "\n",
    "CIVICPULSE_DEVICE={DEVICE.type}\n",
    "CIVICPULSE_BATCH_SIZE={best_bs}\n",
    "CIVICPULSE_DATA_MODE={best_lm}\n",
    "CIVICPULSE_PATCH_SIZE={best_ps}\n",
    "\n",
    "# ConvLSTM Architecture (set in src/config.py TrainingConfig)\n",
    "# HIDDEN_CHANNELS = {best_ar.get('hidden', 32)}\n",
    "# NUM_LAYERS      = {best_ar.get('layers', 2)}\n",
    "\"\"\"\n",
    "\n",
    "print(env_block)\n",
    "\n",
    "print(\"üìã Copy the block above into your .env file.\")\n",
    "print(\"   Then update TrainingConfig in src/config.py for the architecture values.\")\n",
    "print(\"   Then set LOAD_MODE in Notebooks 04-07 to match CIVICPULSE_DATA_MODE.\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"PERFORMANCE BENCHMARKING COMPLETE ‚úÖ\")\n",
    "print(\"Next: Notebook 04 ‚Äî Model Architecture (use values above)\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-sanity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running sanity forward pass with recommended config...\n",
      "  Input  : (32, 4, 1, 256, 256)\n",
      "  Output : (32, 1, 256, 256)\n",
      "  Range  : -0.62 ‚Äì 0.63\n",
      "  Params : 333,953\n",
      "‚úÖ Sanity pass OK ‚Äî model runs cleanly with recommended config\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Sanity check: one real forward pass with best config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\nRunning sanity forward pass with recommended config...\")\n",
    "\n",
    "try:\n",
    "    _hc = best_ar.get(\"hidden\", 32)\n",
    "    _nl = best_ar.get(\"layers\", 2)\n",
    "    _ps = best_ps if valid_ps else 64\n",
    "    _bs = best_bs if isinstance(best_bs, int) else 4\n",
    "\n",
    "    model = ConvLSTMEncoderDecoder(\n",
    "        hidden_channels=_hc, num_layers=_nl).to(DEVICE)\n",
    "\n",
    "    # Use a real patch from the HDF5 file\n",
    "    with h5py.File(H5_PATH, \"r\") as h5:\n",
    "        patch = h5[\"population_data\"][:, :_ps, :_ps]   # (5, ps, ps)\n",
    "\n",
    "    X_real = torch.from_numpy(patch[:4]).float().unsqueeze(0).unsqueeze(2).to(DEVICE)\n",
    "    # shape: (1, 4, 1, ps, ps)\n",
    "    X_batch = X_real.expand(_bs, -1, -1, -1, -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(X_batch)\n",
    "\n",
    "    print(f\"  Input  : {tuple(X_batch.shape)}\")\n",
    "    print(f\"  Output : {tuple(out.shape)}\")\n",
    "    print(f\"  Range  : {out.min().item():.2f} ‚Äì {out.max().item():.2f}\")\n",
    "    print(f\"  Params : {count_params(model):,}\")\n",
    "    print(\"‚úÖ Sanity pass OK ‚Äî model runs cleanly with recommended config\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Sanity pass failed: {e}\")\n",
    "    import traceback; traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0fabf5-48c7-4c70-94ca-bc5663754226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
