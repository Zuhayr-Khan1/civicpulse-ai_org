{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa44793e-b916-40b7-9587-ba7676e76d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NOTEBOOK 04 â€” MODEL ARCHITECTURE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ðŸš€ CIVICPULSE TRAINING CONFIGURATION (Benchmark-Optimized)\n",
      "======================================================================\n",
      "Device           : cpu\n",
      "VRAM Available   : 0.0 GB\n",
      "Batch Size       : 32\n",
      "Data Mode        : normal\n",
      "Patch Size       : 256Ã—256 cells\n",
      "ConvLSTM         : 64 hidden, 2 layers\n",
      "Learning Rate    : 0.001\n",
      "Sequence Length  : 4 timesteps\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 â€” Imports + Config\n",
    "import sys, os, torch, torch.nn as nn, torch.optim as optim\n",
    "import numpy as np, h5py, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm as tqdm_nb\n",
    "from datetime import datetime\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from src.config import TrainingConfig\n",
    "\n",
    "config    = TrainingConfig()\n",
    "device    = config.DEVICE\n",
    "LOAD_MODE = config.DATA_MODE   # â† from .env, no manual edit needed\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NOTEBOOK 04 â€” MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 70)\n",
    "config.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e02126-c9cb-466b-986c-edc5599867f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 â€” ConvLSTM Cell\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        padding = kernel_size // 2\n",
    "        self.conv_gates = nn.Conv2d(\n",
    "            in_channels + hidden_channels, 2 * hidden_channels, kernel_size, padding=padding)\n",
    "        self.conv_candidate = nn.Conv2d(\n",
    "            in_channels + hidden_channels, hidden_channels, kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, inputs, hidden_state):\n",
    "        h, c = hidden_state\n",
    "        combined = torch.cat([inputs, h], dim=1)\n",
    "        gates = self.conv_gates(combined)\n",
    "        reset_gate, update_gate = torch.split(gates, self.hidden_channels, dim=1)\n",
    "        reset_gate  = torch.sigmoid(reset_gate)\n",
    "        update_gate = torch.sigmoid(update_gate)\n",
    "        combined_candidate = torch.cat([inputs, reset_gate * h], dim=1)\n",
    "        candidate = torch.tanh(self.conv_candidate(combined_candidate))\n",
    "        new_c = (1 - update_gate) * c + update_gate * candidate\n",
    "        new_h = torch.tanh(new_c) * update_gate + (1 - update_gate) * h\n",
    "        return new_h, new_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc82099b-0b55-434f-ac26-3242ceaaebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 â€” ConvLSTM Encoder-Decoder\n",
    "class ConvLSTMEncoderDecoder(nn.Module):\n",
    "    def __init__(self, in_channels=1,\n",
    "                 hidden_channels=None, num_layers=None, kernel_size=3):\n",
    "        super().__init__()\n",
    "        # Pull from config if not explicitly passed\n",
    "        _cfg = TrainingConfig()\n",
    "        hidden_channels = hidden_channels or _cfg.HIDDEN_CHANNELS\n",
    "        num_layers      = num_layers      or _cfg.NUM_LAYERS\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers      = num_layers\n",
    "        self.encoder_cells = nn.ModuleList([\n",
    "            ConvLSTMCell(in_channels if i == 0 else hidden_channels,\n",
    "                         hidden_channels, kernel_size)\n",
    "            for i in range(num_layers)])\n",
    "        self.decoder_cells = nn.ModuleList([\n",
    "            ConvLSTMCell(hidden_channels, hidden_channels, kernel_size)\n",
    "            for _ in range(num_layers)])\n",
    "        self.output_conv = nn.Conv2d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        h = [torch.zeros(B, self.hidden_channels, H, W, device=x.device, dtype=x.dtype)\n",
    "             for _ in range(self.num_layers)]\n",
    "        c = [torch.zeros(B, self.hidden_channels, H, W, device=x.device, dtype=x.dtype)\n",
    "             for _ in range(self.num_layers)]\n",
    "        for t in range(T):\n",
    "            xt = x[:, t]\n",
    "            for layer in range(self.num_layers):\n",
    "                h[layer], c[layer] = self.encoder_cells[layer](\n",
    "                    xt if layer == 0 else h[layer-1], (h[layer], c[layer]))\n",
    "        for layer in range(self.num_layers):\n",
    "            inp = h[layer-1] if layer > 0 else h[0]\n",
    "            h[layer], c[layer] = self.decoder_cells[layer](inp, (h[layer], c[layer]))\n",
    "        return self.output_conv(h[-1])   # (B, 1, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e333d2-fa8f-49c4-901f-6fe18452c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Normal mode: full numpy load...\n",
      "  Loaded shape: (5, 256, 256)\n",
      "Parameters: 776,705\n",
      "Output shape : torch.Size([1, 1, 256, 256])\n",
      "Output range : -0.3 â€“ 0.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 â€” Load Test Data (mode-aware)\n",
    "h5_path = \"data/processed/india_sample.h5\"\n",
    "\n",
    "if LOAD_MODE == \"hdf5\":\n",
    "    print(\"ðŸ“‚ HDF5 mode: lazy-loading patch for test...\")\n",
    "    with h5py.File(h5_path, \"r\") as h5:\n",
    "        data = h5[\"population_data\"][:, :256, :256]\n",
    "    print(f\"  Loaded patch: {data.shape}\")\n",
    "else:\n",
    "    print(\"ðŸ“‚ Normal mode: full numpy load...\")\n",
    "    tel_seq  = np.load(\"data/processed/telangana_population_sequence.npy\")\n",
    "    maha_seq = np.load(\"data/processed/maharashtra_population_sequence.npy\")\n",
    "    T, H1, W1 = tel_seq.shape\n",
    "    _,  H2, W2 = maha_seq.shape\n",
    "    maxH, maxW = max(H1, H2), max(W1, W2)\n",
    "    tel_seq  = np.pad(tel_seq,  ((0,0),(0,maxH-H1),(0,maxW-W1)))\n",
    "    maha_seq = np.pad(maha_seq, ((0,0),(0,maxH-H2),(0,maxW-W2)))\n",
    "    data = np.concatenate([tel_seq, maha_seq], axis=1)[:, :256, :256]\n",
    "    print(f\"  Loaded shape: {data.shape}\")\n",
    "\n",
    "X_test = torch.from_numpy(data[:4]).float().unsqueeze(0).unsqueeze(2)  # (1,4,1,256,256)\n",
    "y_test = torch.from_numpy(data[4]).float().unsqueeze(0).unsqueeze(0)   # (1,1,256,256)\n",
    "\n",
    "model = ConvLSTMEncoderDecoder().to(device)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(X_test.to(device))\n",
    "print(f\"Output shape : {output.shape}\")\n",
    "print(f\"Output range : {output.min().item():.1f} â€“ {output.max().item():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ffb456-7bba-456c-8c96-930659491fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model classes and loss function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 â€” Loss + Metrics\n",
    "class PopulationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha, self.beta = alpha, beta\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.mae = nn.L1Loss()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        mse  = self.mse(pred, target)\n",
    "        mae  = self.mae(pred, target)\n",
    "        pc   = torch.clamp(pred,   min=0)\n",
    "        tc   = torch.clamp(target, min=0)\n",
    "        mask = tc > 1.0\n",
    "        rel  = (torch.abs(pc[mask] - tc[mask]) / (tc[mask] + 1e-8)).mean() \\\n",
    "               if mask.sum() > 0 else torch.tensor(0.0, device=pred.device)\n",
    "        return self.alpha * mse + self.beta * mae + 0.1 * rel\n",
    "\n",
    "def calculate_r2(pred, target):\n",
    "    ss_res = ((pred - target) ** 2).sum()\n",
    "    ss_tot = ((target - target.mean()) ** 2).sum()\n",
    "    return (1 - ss_res / ss_tot).item()\n",
    "\n",
    "criterion = PopulationLoss()\n",
    "print(\"âœ… Model classes and loss function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d5c746-f016-4e2b-bb2b-cc584db18b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: models/model_architecture.pt\n",
      "======================================================================\n",
      "NOTEBOOK 04 COMPLETE â€” Next: Notebook 05 Training\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 â€” Save architecture\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), \"models/model_architecture.pt\")\n",
    "print(\"âœ… Saved: models/model_architecture.pt\")\n",
    "print(\"=\" * 70)\n",
    "print(\"NOTEBOOK 04 COMPLETE â€” Next: Notebook 05 Training\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f65de-6556-4ffe-b2ec-a7a30a3fb990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
