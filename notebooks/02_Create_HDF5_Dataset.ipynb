{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63481bf-0272-474f-931e-705ebd18298a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HDF5 dataset for efficient memory usage...\n",
      "Benefit: Load 40GB dataset with only 2GB active memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Creating HDF5 dataset for efficient memory usage...\")\n",
    "print(\"Benefit: Load 40GB dataset with only 2GB active memory\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c074b633-8d2f-4af6-9c7a-51acc75cdad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading interpolated state data...\n",
      "Telangana shape: (5, 517, 469)\n",
      "Maharashtra shape: (5, 817, 997)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading interpolated state data...\")\n",
    "\n",
    "tel_seq = np.load('data/processed/telangana_population_sequence.npy')\n",
    "maha_seq = np.load('data/processed/maharashtra_population_sequence.npy')\n",
    "\n",
    "print(f\"Telangana shape: {tel_seq.shape}\")\n",
    "print(f\"Maharashtra shape: {maha_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5fc91c-ad5d-4ca0-a25f-876ed4b8b23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aligning dimensions...\n",
      "After padding:\n",
      "  Telangana: (5, 817, 997)\n",
      "  Maharashtra: (5, 817, 997)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAligning dimensions...\")\n",
    "\n",
    "tel_h, tel_w = tel_seq.shape[1:]\n",
    "maha_h, maha_w = maha_seq.shape[1:]\n",
    "\n",
    "max_h = max(tel_h, maha_h)\n",
    "max_w = max(tel_w, maha_w)\n",
    "\n",
    "# Pad if needed\n",
    "tel_padded = np.pad(tel_seq, \n",
    "                   ((0, 0), (0, max_h - tel_h), (0, max_w - tel_w)),\n",
    "                   mode='constant', constant_values=0)\n",
    "\n",
    "maha_padded = np.pad(maha_seq,\n",
    "                    ((0, 0), (0, max_h - maha_h), (0, max_w - maha_w)),\n",
    "                    mode='constant', constant_values=0)\n",
    "\n",
    "print(f\"After padding:\")\n",
    "print(f\"  Telangana: {tel_padded.shape}\")\n",
    "print(f\"  Maharashtra: {maha_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9493d9fe-0261-4d40-8e0b-f49cd8a637ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating HDF5 file...\n",
      "Writing Telangana...\n",
      "Writing Maharashtra...\n",
      "\n",
      "✅ HDF5 created: data/processed/india_sample.h5\n",
      "✅ File size: 18.4 MB (compressed from 32.6 MB)\n",
      "✅ Compression ratio: 1.8x\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating HDF5 file...\")\n",
    "\n",
    "h5_path = 'data/processed/india_sample.h5'\n",
    "\n",
    "with h5py.File(h5_path, 'w') as h5:\n",
    "    # Create dataset with chunking (1 timestep, 256x256 spatial)\n",
    "    dataset = h5.create_dataset(\n",
    "        'population_data',\n",
    "        shape=(\n",
    "            tel_padded.shape[0],                           # 5 years\n",
    "            tel_padded.shape[1] + maha_padded.shape[1],    # Stacked states\n",
    "            tel_padded.shape[2]                             # Width\n",
    "        ),\n",
    "        dtype=np.float32,\n",
    "        chunks=(1, 256, 256),           # Chunk for lazy loading\n",
    "        compression='gzip',              # Compression\n",
    "        compression_opts=4               # Balance speed vs ratio\n",
    "    )\n",
    "    \n",
    "    # Write data\n",
    "    print(\"Writing Telangana...\")\n",
    "    h5['population_data'][:, :tel_padded.shape[1], :] = tel_padded\n",
    "    \n",
    "    print(\"Writing Maharashtra...\")\n",
    "    h5['population_data'][:, tel_padded.shape[1]:, :] = maha_padded\n",
    "    \n",
    "    # Add metadata\n",
    "    h5.attrs['description'] = 'India sample state population data'\n",
    "    h5.attrs['years'] = '2000, 2005, 2010, 2015, 2020'\n",
    "    h5.attrs['states'] = 'Telangana (top), Maharashtra (bottom)'\n",
    "    h5.attrs['resolution_km'] = 1.0\n",
    "\n",
    "file_size_mb = Path(h5_path).stat().st_size / 1e6\n",
    "orig_size_mb = (tel_padded.nbytes + maha_padded.nbytes) / 1e6\n",
    "\n",
    "print(f\"\\n✅ HDF5 created: {h5_path}\")\n",
    "print(f\"✅ File size: {file_size_mb:.1f} MB (compressed from {orig_size_mb:.1f} MB)\")\n",
    "print(f\"✅ Compression ratio: {orig_size_mb/file_size_mb:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9efb90c5-6e05-4bc9-a3a6-a54348cb6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying HDF5...\n",
      "Dataset shape: (5, 1634, 997)\n",
      "Chunk shape: (1, 256, 256)\n",
      "\n",
      "Metadata:\n",
      "  description: India sample state population data\n",
      "  resolution_km: 1.0\n",
      "  states: Telangana (top), Maharashtra (bottom)\n",
      "  years: 2000, 2005, 2010, 2015, 2020\n",
      "\n",
      "Testing lazy loading...\n",
      "✅ Loaded single year in 0.057s\n",
      "✅ Data range: 0 - 63067\n",
      "✅ Memory: only ~16MB loaded per timestep\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerifying HDF5...\")\n",
    "\n",
    "with h5py.File(h5_path, 'r') as h5:\n",
    "    print(f\"Dataset shape: {h5['population_data'].shape}\")\n",
    "    print(f\"Chunk shape: {h5['population_data'].chunks}\")\n",
    "    \n",
    "    print(f\"\\nMetadata:\")\n",
    "    for key in h5.attrs:\n",
    "        print(f\"  {key}: {h5.attrs[key]}\")\n",
    "    \n",
    "    # Test lazy loading\n",
    "    print(f\"\\nTesting lazy loading...\")\n",
    "    import time\n",
    "    \n",
    "    start = time.time()\n",
    "    data_2000 = h5['population_data'][0, :, :]\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"✅ Loaded single year in {elapsed:.3f}s\")\n",
    "    print(f\"✅ Data range: {data_2000.min():.0f} - {data_2000.max():.0f}\")\n",
    "    print(f\"✅ Memory: only ~{tel_padded.nbytes/1e6:.0f}MB loaded per timestep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17cabc5-c4ab-429f-84c4-381adbcffbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HDF5 CREATION COMPLETE ✅\n",
      "======================================================================\n",
      "\n",
      "Dataset ready: data/processed/india_sample.h5\n",
      "Next: Notebook 03 - Clip Full India (8-12 hour operation)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HDF5 CREATION COMPLETE ✅\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDataset ready: data/processed/india_sample.h5\")\n",
    "print(f\"Next: Notebook 03 - Clip Full India (8-12 hour operation)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
